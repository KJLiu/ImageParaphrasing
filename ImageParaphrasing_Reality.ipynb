{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "# from utils import receptive_field_computer\n",
    "from utils import *\n",
    "import itertools\n",
    "from neural_style import build_model\n",
    "# from models_bedroom import *\n",
    "from nets import *\n",
    "from scipy.misc import imsave\n",
    "\n",
    "nsample = 64\n",
    "ntimes = 1\n",
    "nimages = 5008\n",
    "\n",
    "# Hyperparameter for Part Change\n",
    "SHOW_IMAGE = False\n",
    "npx_list = [64]\n",
    "# lr_list = [8e-3 * 2**i for i in range(-6,7)]\n",
    "lr_list = [9e-2] # For adam\n",
    "# lr_list = [1e3] # For sgd [1e3] or [1e2]\n",
    "max_step_list = [300]\n",
    "main_coef_list = [1. * 1e6 ]\n",
    "mask_pos_list = [None]\n",
    "mask_prob_list = [0.5]\n",
    "b1 = 0.4\n",
    "b2 = 0.99\n",
    "# b1=0.2\n",
    "# b2=0.5\n",
    "\n",
    "\n",
    "# Discriminator \n",
    "alpha_list = [0.]\n",
    "\n",
    "# Pixel Space\n",
    "gamma_list = [0.]#[0.1/255.]\n",
    "\n",
    "noise_coef_list =  [0.0005]\n",
    "# a = 2e-7\n",
    "# b = 1.5e-7\n",
    "# n = 5\n",
    "# noise_coef_list =  list(np.arange(b,a,(a-b)/n))\n",
    "\n",
    "\n",
    "\n",
    "# content_layers_list = [['relu%d_%d'%(1,1), 'relu%d_%d'%(2,1), 'relu%d_%d'%(3,1), 'relu%d_%d'%(4,1),'relu%d_%d'%(5,1)]]\n",
    "# content_weights_list = [[0, 2, 3, 10, 0.]]\n",
    "# content_types_list = [['Feature','Feature','Feature','Feature','Feature']]\n",
    "# mask_types_list = [['main', 'main', 'main', 'main', 'main']]\n",
    "\n",
    "# content_layers_list = [['relu%d_%d'%(3,1), 'relu%d_%d'%(4,1)]]\n",
    "# content_weights_list = [[7, 10]]\n",
    "# content_types_list = [['Feature','Feature']]\n",
    "# mask_types_list = [[ 'main', 'main']]\n",
    "\n",
    "content_layers_list = [['relu%d_%d'%(4,1)]]\n",
    "content_weights_list = [[1]]\n",
    "content_types_list = [['Feature']]\n",
    "mask_types_list = [[ 'main']]\n",
    "\n",
    "\n",
    "\n",
    "# content_types_list = [['Feature','Feature']]\n",
    "\n",
    "# mask_types_list = [['main', 'comp']]\n",
    "\n",
    "# content_types_list = [['Feature', 'Feature', 'Feature', 'Feature', 'Feature', 'Feature']]\n",
    "# content_layers_list = [['conv%d_%d'%(1,2),'conv%d_%d'%(2,2),'conv%d_%d'%(3,1), 'conv%d_%d'%(4,1), 'conv%d_%d'%(5,1)] ] \n",
    "# CONTENT_LOSS_TYPE = 'Gram'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dataset = 'Bedroom'\n",
    "result_path = 'Results_%s_test_images_5000_smallVar'%Dataset\n",
    "\n",
    "# n_list = [str(i) for i in np.random.randint(10000, size=1)]\n",
    "# n_list = ['0001256'] #Red bed\n",
    "\n",
    "# content_img_paths = ['../BEGAN-tensorflow/data/Bedroom/splits/train/%s.jpg'%n.zfill(7) for n in n_list]\n",
    "if Dataset == 'Bedroom':\n",
    "#     n_list = ['4596']\n",
    "    \n",
    "#     n_list = [str(i) for i in np.random.randint(50000, size=nimages)]\n",
    "    filelist = listfile('/home/tim/kjliu/project-file/data/Bedroom/splits/test/')\n",
    "    content_img_paths = [filelist[i] for i in np.random.randint(low = 0, high = len(filelist), size=nimages)]\n",
    "    content_img_paths = [content_img_paths[t*nsample:(t+1)*nsample] for t in range(nimages//nsample)]\n",
    "elif Dataset == 'CelebA':\n",
    "#     n_list = [str(i) for i in np.random.randint(19962, size=nimages)]\n",
    "\n",
    "#     n_list = ['870'] #['23245]\n",
    "#     content_img_paths = ['/home/tim/kjliu/project-file/data/CelebA/splits/train/%s.jpg'%n.zfill(6) for n in n_list]\n",
    "    \n",
    "    filelist = listfile('/home/tim/kjliu/project-file/data/CelebA/splits/test/')\n",
    "    content_img_paths = [filelist[i] for i in np.random.randint(low = 0, high = len(filelist), size=nimages)]\n",
    "    content_img_paths = [content_img_paths[t*nsample:(t+1)*nsample] for t in range(nimages//nsample)]\n",
    "hyper_lists=[npx_list\n",
    "           ,lr_list\n",
    "           ,max_step_list\n",
    "           ,main_coef_list\n",
    "           ,mask_pos_list\n",
    "           ,alpha_list\n",
    "           ,gamma_list\n",
    "           ,noise_coef_list\n",
    "           ,content_layers_list\n",
    "           ,content_weights_list\n",
    "           ,content_types_list\n",
    "           ,mask_prob_list\n",
    "           ,mask_types_list\n",
    "           ,content_img_paths\n",
    "            ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_hyperparameter(hyperparameters, root_path):\n",
    "    global npx, lr, max_step, main_coef, mask_pos, mask, prob, gram_mask\n",
    "    global alpha, recon_mask\n",
    "    global gamma, pixel_mask\n",
    "    global noise_coef\n",
    "    global content_layers, content_weights, content_types\n",
    "    global mask_types\n",
    "    global b1, b2\n",
    "    global content_img_path\n",
    "    # Hyperparameter for Part Change\n",
    "    npx = hyperparameters[0]\n",
    "    lr = hyperparameters[1]\n",
    "    max_step = hyperparameters[2]\n",
    "    main_coef = hyperparameters[3]\n",
    "    mask_pos = hyperparameters[4]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    noise_coef =  lr * hyperparameters[7]\n",
    "    content_layers = hyperparameters[8]\n",
    "    content_weights = hyperparameters[9] / np.sum(hyperparameters[9])\n",
    "    content_types = hyperparameters[10]\n",
    "    prob = hyperparameters[11]\n",
    "    \n",
    "    mask = 1#-gen_mask(npx, (32,29), blur = 1, prob = 1., rect_size = (30,30)).reshape(npx,npx,1)\n",
    "    #mask = gen_mask(npx, mask_pos, blur = 10, prob = prob).reshape(npx,npx,1)\n",
    "    \n",
    "    # Discriminator \n",
    "    alpha = hyperparameters[5]      \n",
    "    recon_mask = 1 if mask_pos is None else (1-mask)\n",
    "\n",
    "    # Pixel Space\n",
    "    gamma = hyperparameters[6]\n",
    "    pixel_mask = 1 - mask\n",
    "    \n",
    "    mask_types = hyperparameters[12]\n",
    "    content_img_path = hyperparameters[13]\n",
    "    with open(os.path.join(root_path, 'hyperparameters.txt'), 'a') as f:\n",
    "        f.write('\\n\\n\\n')\n",
    "        f.write('')\n",
    "        f.write('npx: %d\\n'%npx)\n",
    "        f.write('lr: %.3E\\n'%lr)\n",
    "        f.write('max_step: %d\\n'%max_step)\n",
    "        f.write('main_coef: %.3E\\n'%main_coef)\n",
    "        f.write('mask_pos: %s\\n'%(mask_pos, ))\n",
    "        f.write('alpha: %.3E\\n'%alpha)\n",
    "        f.write('gamma: %.3E\\n'%gamma)\n",
    "        f.write('noise_coef: %.3E\\n'%noise_coef)\n",
    "        f.write('content_layers: %s\\n'%content_layers)\n",
    "        f.write('content_weights: %s\\n'%content_weights)\n",
    "        f.write('content_types: %s\\n'%content_types)\n",
    "        f.write('mask_prob: %s\\n'%prob)\n",
    "        f.write('beta1: %s\\n'%b1)\n",
    "        f.write('beta2: %s\\n'%b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check reference image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corresponding model architecture\n",
    "- WGAN for Bedroom\n",
    "- BEGAN for CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if Dataset == 'Bedroom':\n",
    "    from gan_64x64 import GeneratorAndDiscriminator\n",
    "    import tflib as lib\n",
    "elif Dataset == 'CelebA':\n",
    "    #Img range [-1, 1]\n",
    "    from models_celeba_began import *\n",
    "# lib.delete_all_params()\n",
    "# print(lib._params, lib._param_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n = [op.name for op in tf.get_default_graph().get_operations() ]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: (64, 0.09, 300, 1000000.0, None, 0.0, 0.0, 0.0005, ['relu4_1'], [1], ['Feature'], 0.5, ['main'], ['/home/tim/kjliu/project-file/data/Bedroom/splits/test/0030050.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0647008.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0750125.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0852840.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1470768.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0543820.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0337955.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0541657.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1262415.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1367003.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0647017.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0747991.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0747621.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1366959.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1056626.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0749216.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1057084.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1366388.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1263680.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0748486.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0233591.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1057405.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1262317.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1057928.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0542322.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0234667.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0029358.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1469472.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1468961.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0441432.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0440812.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0853126.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1056835.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0438997.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0747812.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0644414.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1468812.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1470567.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1160471.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1367121.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0955231.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0850704.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0439399.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0234031.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1366301.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1159285.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1470471.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0542043.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0644186.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0850206.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0337398.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0028249.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1367364.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0542966.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1262113.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0853334.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1470305.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0029087.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0233489.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/1159125.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0027347.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0644934.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0851853.jpg', '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0852146.jpg'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for idx, hyperparameters in enumerate(itertools.product(*hyper_lists)):\n",
    "#     for i in range(100):\n",
    "    print('Hyperparameters: %s'%(hyperparameters,))\n",
    "    ########################### Prepare Experiment ###########################\n",
    "    root_path = os.path.join(result_path, Dataset + '_' + get_time())\n",
    "    mkdir(root_path)\n",
    "    assign_hyperparameter(hyperparameters, root_path)\n",
    "\n",
    "    ########################### Load Content Image ###########################\n",
    "    content_img = read_imgs(content_img_path, npx) \n",
    "    content_img_orig = content_img.copy()\n",
    "    content_img = preprocess(content_img, npx = npx)\n",
    "    \n",
    "\n",
    "    ########################### Build Graph ###########################\n",
    "    if Dataset == 'Bedroom':\n",
    "        with tf.variable_scope('Paraphrasing') as scope:\n",
    "        #     scope.reuse_variables()\n",
    "            paint_board = tf.get_variable('Paint_board', [nsample, 128],initializer=tf.random_normal_initializer())\n",
    "        init_op_paint_board = tf.variables_initializer([paint_board])\n",
    "        generator, discriminator = GeneratorAndDiscriminator()\n",
    "        init_img_orig = generator(nsample, noise=paint_board)\n",
    "        init_img = tf.transpose(tf.reshape(init_img_orig, [-1,3, 64,64]), [0,2,3,1])\n",
    "        init_img = tf.image.resize_nearest_neighbor(init_img, [npx, npx])\n",
    "        init_img = (init_img + 1)/2 * 255.\n",
    "        init_img_vgg = init_img\n",
    "        init_img_vgg = vgg_img(init_img)\n",
    "\n",
    "        init_img_logits = discriminator(init_img_orig) # Bug Need denorm??\n",
    "        g_vars = tf.contrib.framework.get_variables('Generator')\n",
    "        d_vars = tf.contrib.framework.get_variables('Discriminator')\n",
    "        var = g_vars + d_vars\n",
    "        net = build_model(content_img, mask = tf.constant(mask, dtype=tf.float32))\n",
    "    #     net = build_model(vgg_img(content_img), mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net2 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net3 = build_model(content_img, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "        net4 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "    elif Dataset == 'CelebA':\n",
    "        with tf.variable_scope('Paraphrasing') as scope:\n",
    "            paint_board = tf.get_variable('Paint_board', [nsample, 64],initializer=tf.random_uniform_initializer())\n",
    "        init_op_paint_board = tf.variables_initializer([paint_board])\n",
    "\n",
    "        init_img_orig, g_vars = GeneratorCNN(paint_board,128,3,4,'NCHW',reuse=False)\n",
    "        init_img = tf.transpose(init_img_orig, [0,2,3,1])\n",
    "        init_img = tf.image.resize_nearest_neighbor(init_img, [npx, npx])\n",
    "        init_img = (init_img + 1)/2 * 255.\n",
    "        init_img_vgg = vgg_img(init_img)\n",
    "\n",
    "        init_img_recon,_, d_vars = DiscriminatorCNN(init_img_orig,3,64,4,128,'NCHW') # BUG_need denorm\n",
    "\n",
    "        var = g_vars + d_vars\n",
    "\n",
    "        net = build_model(content_img, mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net2 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net3 = build_model(content_img, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "        net4 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "    ########################### Loss ###########################\n",
    "    from time import time\n",
    "    t = time()\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver(var)\n",
    "    \n",
    "    \n",
    "    if Dataset == 'CelebA':\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('logs/CelebA_0517_071609/'))\n",
    "    #elif Dataset == 'Bedroom': # Wrong model(with Batchnorm)\n",
    "    #    saver.restore(sess, tf.train.latest_checkpoint('logs/Bedroom_0726_161928/'))\n",
    "    elif Dataset == 'Bedroom':\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('logs/Bedroom_0812_011108/'))\n",
    "    print(\"Cost time: %.2fs\"%(time() - t))\n",
    "\n",
    "    # content loss\n",
    "    L_content, loss_collections = sum_content_losses(sess, net, net2, net3, net4,\n",
    "                                                     content_img,\n",
    "                                                     content_layers=content_layers,\n",
    "                                                     content_layer_weights=content_weights,\n",
    "                                                     content_types = content_types,\n",
    "                                                     mask_types = mask_types\n",
    "                                                    )\n",
    "\n",
    "    # Discrim loss\n",
    "    if Dataset == 'CelebA':\n",
    "        discrim_loss = tf.reduce_mean(tf.abs(init_img_recon - init_img_orig) )\n",
    "    elif Dataset == 'Bedroom':\n",
    "        discrim_loss = - tf.reduce_mean(init_img_logits)\n",
    "\n",
    "    # total loss\n",
    "    L_total  = main_coef * L_content\n",
    "    alpha_var = tf.get_variable(name='alpha', dtype=tf.float32, initializer=alpha * 1.0)\n",
    "    L_total += alpha_var*discrim_loss\n",
    "    L_total += gamma*tf.reduce_mean(tf.abs(content_img_orig - init_img)*tf.constant((pixel_mask),dtype=tf.float32))\n",
    "    \n",
    "    ############################ optimization algorithm ###############################\n",
    "    init_z = paint_board\n",
    "\n",
    "\n",
    "\n",
    "    with tf.variable_scope('adam_optimizer') as vs:\n",
    "        optimizer = tf.train.AdamOptimizer(lr, beta1=b1, beta2=b2)\n",
    "#         optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "#         optimizer = tf.train.RMSPropOptimizer(lr)\n",
    "\n",
    "        gvs = optimizer.compute_gradients(L_total, var_list=[init_z])\n",
    "        gvs = [(grad+noise_coef*tf.random_normal(tf.shape(grad)), var) for grad, var in gvs]\n",
    "\n",
    "        train_op = optimizer.apply_gradients(gvs)\n",
    "        vars = tf.contrib.framework.get_variables(vs)\n",
    "    init_op = tf.initialize_variables(vars + [alpha_var])    \n",
    "\n",
    "    ########################### Session Run ##########################\n",
    "    output_data = []\n",
    "    for t in range(ntimes):\n",
    "        sess.run(init_op_paint_board)\n",
    "        sess.run(init_op)\n",
    "#         batch_imgs = content_img_pool[t*nsample:(t+1)*nsample].copy()\n",
    "#         sess.run([net['input'].assign(batch_imgs)\n",
    "#                       ,net3['input'].assign(batch_imgs)\n",
    "#                  ]\n",
    "#               )\n",
    "        \n",
    "        \n",
    "        i = sess.run(init_img)\n",
    "        grid_imgs = color_grid_vis(i)        \n",
    "        content_img_orig_grid = color_grid_vis(content_img_orig)\n",
    "        plot_img(content_img_orig_grid/255.\n",
    "                 ,title='Content Img'\n",
    "                 ,save_path=os.path.join(root_path, 'content_img_original.jpg')\n",
    "                 ,show = SHOW_IMAGE\n",
    "                )\n",
    "#         rand = str(np.random.randint(10000))\n",
    "        plot_img(my_post(grid_imgs)\n",
    "                 ,title='Sample Img Init'\n",
    "                 ,save_path=os.path.join(root_path, 'samples_init.jpg')\n",
    "                 ,show=SHOW_IMAGE\n",
    "                )\n",
    "        train_loss = []\n",
    "        for iterations in trange(max_step):\n",
    "            sess.run(train_op)\n",
    "            if iterations % 100 == 0:\n",
    "                curr_loss = sess.run(L_total)\n",
    "                train_loss.append(curr_loss)\n",
    "                img = sess.run(init_img)\n",
    "                grid_imgs = color_grid_vis(img)\n",
    "\n",
    "                print(\"At iterate {}\\tf=  {:.4f}\".format(iterations, curr_loss))\n",
    "    #             loss = sess.run(loss_collections)\n",
    "    #             print(loss)\n",
    "                plot_img(my_post(grid_imgs)\n",
    "                         ,title='Sample Img Iter_%d'%iterations\n",
    "                         ,save_path=os.path.join(root_path, 'samples_iter_%d.png'%iterations)\n",
    "                         ,show=SHOW_IMAGE\n",
    "                        )\n",
    "            if iterations > 99:\n",
    "                if iterations % 100 == 0:\n",
    "                    alpha_var.assign(sess.run(alpha_var) * 1)\n",
    "        img = sess.run(init_img)\n",
    "        output_data.append(img)\n",
    "\n",
    "        grid_imgs = color_grid_vis(img)\n",
    "\n",
    "        print(\"At iterate {}\\tf=  {:.4f}\".format(iterations, curr_loss))\n",
    "        plot_img(my_post(grid_imgs)\n",
    "                 ,title='Sample Img Iter_%d'%iterations\n",
    "                 ,save_path=os.path.join(root_path, 'samples_iter_%d.png'%iterations)\n",
    "                 ,show=SHOW_IMAGE\n",
    "                )\n",
    "\n",
    "        ########################### Plot final learning result & write to file #####################\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(train_loss)) * 100, train_loss, color='blue', label='Train loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.xlabel('#Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        print('Final loss: %.4f'%train_loss[-1])\n",
    "        with open(os.path.join(root_path, 'hyperparameters.txt'), 'a') as f:\n",
    "            f.write('Final loss: %d\\n'%train_loss[-1])\n",
    "    output_data = np.concatenate(output_data)\n",
    "    for idx, (pic, con) in enumerate(zip(output_data, content_img_orig)):\n",
    "        imsave(os.path.join(root_path, '%s.png'%str(idx).zfill(5)),my_post(pic) )\n",
    "        imsave(os.path.join(root_path, '%s_content.png'%str(idx).zfill(5)),my_post(con) )\n",
    "    \n",
    "    plot_compared(img, content_img_orig,save_path=os.path.join(root_path, 'ComparedResults.png') , show = SHOW_IMAGE)\n",
    "    ########################### Close Session & Reset Graph\n",
    "    tf.reset_default_graph()\n",
    "    #sess.close()\n",
    "    if Dataset == 'Bedroom':\n",
    "        lib.delete_all_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python msssim_Copy1.py --original_image=187628.jpg --compared_image=187627.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !python msssim.py --path=./ --nsamples=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
