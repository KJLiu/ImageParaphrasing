{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "# from utils import receptive_field_computer\n",
    "from utils import *\n",
    "import itertools\n",
    "from neural_style import build_model\n",
    "# from models_bedroom import *\n",
    "from nets import *\n",
    "from scipy.misc import imsave\n",
    "\n",
    "nsample = 64\n",
    "ntimes = 4\n",
    "nimages = 40\n",
    "\n",
    "# Hyperparameter for Part Change\n",
    "SHOW_IMAGE = False\n",
    "npx_list = [64]\n",
    "# lr_list = [8e-3 * 2**i for i in range(-6,7)]\n",
    "lr_list = [9e-2] # For adam\n",
    "# lr_list = [1e3] # For sgd [1e3] or [1e2]\n",
    "max_step_list = [1000]\n",
    "main_coef_list = [1.]\n",
    "mask_pos_list = [None]\n",
    "mask_prob_list = [0.5]\n",
    "b1 = 0.4\n",
    "b2 = 0.99\n",
    "# b1=0.2\n",
    "# b2=0.5\n",
    "\n",
    "\n",
    "# Discriminator \n",
    "alpha_list = [0.]\n",
    "\n",
    "# Pixel Space\n",
    "gamma_list = [0.]#[0.1/255.]\n",
    "\n",
    "noise_coef_list =  [0.0005]\n",
    "# a = 2e-7\n",
    "# b = 1.5e-7\n",
    "# n = 5\n",
    "# noise_coef_list =  list(np.arange(b,a,(a-b)/n))\n",
    "\n",
    "\n",
    "\n",
    "# content_layers_list = [['relu%d_%d'%(1,1), 'relu%d_%d'%(2,1), 'relu%d_%d'%(3,1), 'relu%d_%d'%(4,1),'relu%d_%d'%(5,1)]]\n",
    "# content_weights_list = [[0, 2, 3, 10, 0.]]\n",
    "# content_types_list = [['Feature','Feature','Feature','Feature','Feature']]\n",
    "# mask_types_list = [['main', 'main', 'main', 'main', 'main']]\n",
    "\n",
    "# content_layers_list = [['relu%d_%d'%(3,1), 'relu%d_%d'%(4,1)]]\n",
    "# content_weights_list = [[7, 10]]\n",
    "# content_types_list = [['Feature','Feature']]\n",
    "# mask_types_list = [[ 'main', 'main']]\n",
    "\n",
    "content_layers_list = [['relu%d_%d'%(4,1)]]\n",
    "content_weights_list = [[1]]\n",
    "content_types_list = [['Feature']]\n",
    "mask_types_list = [[ 'main']]\n",
    "\n",
    "Dataset = 'Bedroom'\n",
    "result_path = 'Results_%s_test_images_smallVar_1000iters'%Dataset\n",
    "\n",
    "# n_list = [str(i) for i in np.random.randint(10000, size=1)]\n",
    "# n_list = ['0001256'] #Red bed\n",
    "\n",
    "# content_img_paths = ['../BEGAN-tensorflow/data/Bedroom/splits/train/%s.jpg'%n.zfill(7) for n in n_list]\n",
    "if Dataset == 'Bedroom':\n",
    "#     n_list = ['4596']\n",
    "    \n",
    "#     n_list = [str(i) for i in np.random.randint(50000, size=nimages)]\n",
    "    filelist = listfile('/home/tim/kjliu/project-file/data/Bedroom/splits/test/')\n",
    "    content_img_paths = [filelist[i] for i in np.random.randint(low = 0, high = len(filelist), size=nimages)]\n",
    "elif Dataset == 'CelebA':\n",
    "#     n_list = [str(i) for i in np.random.randint(19962, size=nimages)]\n",
    "\n",
    "#     n_list = ['870'] #['23245]\n",
    "#     content_img_paths = ['/home/tim/kjliu/project-file/data/CelebA/splits/train/%s.jpg'%n.zfill(6) for n in n_list]\n",
    "    \n",
    "    filelist = listfile('/home/tim/kjliu/project-file/data/CelebA/splits/test/')\n",
    "    content_img_paths = [filelist[i] for i in np.random.randint(low = 0, high = len(filelist), size=nimages)]\n",
    "\n",
    "hyper_lists=[npx_list\n",
    "           ,lr_list\n",
    "           ,max_step_list\n",
    "           ,main_coef_list\n",
    "           ,mask_pos_list\n",
    "           ,alpha_list\n",
    "           ,gamma_list\n",
    "           ,noise_coef_list\n",
    "           ,content_layers_list\n",
    "           ,content_weights_list\n",
    "           ,content_types_list\n",
    "           ,mask_prob_list\n",
    "           ,mask_types_list\n",
    "           ,content_img_paths\n",
    "            ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_hyperparameter(hyperparameters, root_path):\n",
    "    global npx, lr, max_step, main_coef, mask_pos, mask, prob, gram_mask\n",
    "    global alpha, recon_mask\n",
    "    global gamma, pixel_mask\n",
    "    global noise_coef\n",
    "    global content_layers, content_weights, content_types\n",
    "    global mask_types\n",
    "    global b1, b2\n",
    "    global content_img_path\n",
    "    # Hyperparameter for Part Change\n",
    "    npx = hyperparameters[0]\n",
    "    lr = hyperparameters[1]\n",
    "    max_step = hyperparameters[2]\n",
    "    main_coef = hyperparameters[3]\n",
    "    mask_pos = hyperparameters[4]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    noise_coef =  lr * hyperparameters[7]\n",
    "    content_layers = hyperparameters[8]\n",
    "    content_weights = hyperparameters[9] / np.sum(hyperparameters[9])\n",
    "    content_types = hyperparameters[10]\n",
    "    prob = hyperparameters[11]\n",
    "    \n",
    "    mask = 1#-gen_mask(npx, (32,29), blur = 1, prob = 1., rect_size = (30,30)).reshape(npx,npx,1)\n",
    "    #mask = gen_mask(npx, mask_pos, blur = 10, prob = prob).reshape(npx,npx,1)\n",
    "    \n",
    "    # Discriminator \n",
    "    alpha = hyperparameters[5]      \n",
    "    recon_mask = 1 if mask_pos is None else (1-mask)\n",
    "\n",
    "    # Pixel Space\n",
    "    gamma = hyperparameters[6]\n",
    "    pixel_mask = 1 - mask\n",
    "    \n",
    "    mask_types = hyperparameters[12]\n",
    "    content_img_path = hyperparameters[13]\n",
    "    with open(os.path.join(root_path, 'hyperparameters.txt'), 'a') as f:\n",
    "        f.write('\\n\\n\\n')\n",
    "        f.write('')\n",
    "        f.write('npx: %d\\n'%npx)\n",
    "        f.write('lr: %.3E\\n'%lr)\n",
    "        f.write('max_step: %d\\n'%max_step)\n",
    "        f.write('main_coef: %.3E\\n'%main_coef)\n",
    "        f.write('mask_pos: %s\\n'%(mask_pos, ))\n",
    "        f.write('alpha: %.3E\\n'%alpha)\n",
    "        f.write('gamma: %.3E\\n'%gamma)\n",
    "        f.write('noise_coef: %.3E\\n'%noise_coef)\n",
    "        f.write('content_layers: %s\\n'%content_layers)\n",
    "        f.write('content_weights: %s\\n'%content_weights)\n",
    "        f.write('content_types: %s\\n'%content_types)\n",
    "        f.write('mask_prob: %s\\n'%prob)\n",
    "        f.write('beta1: %s\\n'%b1)\n",
    "        f.write('beta2: %s\\n'%b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb39b53b940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = read_img(content_img_paths[0])\n",
    "print(img.shape)\n",
    "plot_img(img/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corresponding model architecture\n",
    "- WGAN for Bedroom\n",
    "- BEGAN for CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if Dataset == 'Bedroom':\n",
    "    from gan_64x64 import GeneratorAndDiscriminator\n",
    "    import tflib as lib\n",
    "elif Dataset == 'CelebA':\n",
    "    #Img range [-1, 1]\n",
    "    from models_celeba_began import *\n",
    "# lib.delete_all_params()\n",
    "# print(lib._params, lib._param_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n = [op.name for op in tf.get_default_graph().get_operations() ]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: (64, 0.09, 1000, 1.0, None, 0.0, 0.0, 0.0005, ['relu4_1'], [1], ['Feature'], 0.5, ['main'], '/home/tim/kjliu/project-file/data/Bedroom/splits/test/0440132.jpg')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for idx, hyperparameters in enumerate(itertools.product(*hyper_lists)):\n",
    "#     for i in range(100):\n",
    "    print('Hyperparameters: %s'%(hyperparameters,))\n",
    "    ########################### Prepare Experiment ###########################\n",
    "    root_path = os.path.join(result_path, Dataset + '_' + get_time())\n",
    "    mkdir(root_path)\n",
    "    assign_hyperparameter(hyperparameters, root_path)\n",
    "\n",
    "    ########################### Load Content Image ###########################\n",
    "#     if len(content_img_paths) > 1:\n",
    "#         content_img = read_imgs(content_img_paths, npx) \n",
    "#     else:\n",
    "#         content_img = read_img(content_img_paths[0], npx)\n",
    "    content_img = read_img(content_img_path, npx)\n",
    "    content_img_orig = content_img.copy()\n",
    "    #content_img = content_img.reshape(-1,npx,npx,3)\n",
    "    content_img = preprocess(content_img, npx = npx)\n",
    "\n",
    "#     if len(content_img_paths) > 1:\n",
    "#         content_img_orig_grid = color_grid_vis(content_img_orig)\n",
    "#         plot_img(content_img_orig_grid/255.\n",
    "#                  ,title='Content Img'\n",
    "#                  ,save_path=os.path.join(root_path, 'content_img_original.jpg')\n",
    "#                  ,show = SHOW_IMAGE\n",
    "#                 )\n",
    "#     else:\n",
    "    content_img_orig_grid = content_img_orig\n",
    "    plot_img(content_img_orig/255.\n",
    "             ,title='Content Img'\n",
    "             ,save_path=os.path.join(root_path, 'content_img_original.jpg')\n",
    "             ,show = SHOW_IMAGE\n",
    "             )\n",
    "\n",
    "    plot_img(content_img_orig * mask / 255.\n",
    "             ,title='Masked Content Img'\n",
    "             ,save_path=os.path.join(root_path, 'masked_ContImg.jpg')\n",
    "             ,show = SHOW_IMAGE\n",
    "            )\n",
    "    \n",
    "    \n",
    "\n",
    "    ########################### Build Graph ###########################\n",
    "    if Dataset == 'Bedroom':\n",
    "        with tf.variable_scope('Paraphrasing') as scope:\n",
    "        #     scope.reuse_variables()\n",
    "           paint_board = tf.get_variable('Paint_board', [nsample, 128],initializer=tf.random_normal_initializer())\n",
    "        init_op_paint_board = tf.variables_initializer([paint_board])\n",
    "        generator, discriminator = GeneratorAndDiscriminator()\n",
    "        init_img_orig = generator(nsample, noise=paint_board)\n",
    "        init_img = tf.transpose(tf.reshape(init_img_orig, [-1,3, 64,64]), [0,2,3,1])\n",
    "        init_img = tf.image.resize_nearest_neighbor(init_img, [npx, npx])\n",
    "        init_img = (init_img + 1)/2 * 255.\n",
    "        init_img_vgg = init_img\n",
    "        init_img_vgg = vgg_img(init_img)\n",
    "\n",
    "        init_img_logits = discriminator(init_img_orig) # Bug Need denorm??\n",
    "        g_vars = tf.contrib.framework.get_variables('Generator')\n",
    "        d_vars = tf.contrib.framework.get_variables('Discriminator')\n",
    "        var = g_vars + d_vars\n",
    "        net = build_model(content_img, mask = tf.constant(mask, dtype=tf.float32))\n",
    "    #     net = build_model(vgg_img(content_img), mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net2 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net3 = build_model(content_img, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "        net4 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "    elif Dataset == 'CelebA':\n",
    "        with tf.variable_scope('Paraphrasing') as scope:\n",
    "            paint_board = tf.get_variable('Paint_board', [nsample, 64],initializer=tf.random_uniform_initializer())\n",
    "        init_op_paint_board = tf.variables_initializer([paint_board])\n",
    "\n",
    "        init_img_orig, g_vars = GeneratorCNN(paint_board,128,3,4,'NCHW',reuse=False)\n",
    "        init_img = tf.transpose(init_img_orig, [0,2,3,1])\n",
    "        init_img = tf.image.resize_nearest_neighbor(init_img, [npx, npx])\n",
    "        init_img = (init_img + 1)/2 * 255.\n",
    "        init_img_vgg = vgg_img(init_img)\n",
    "\n",
    "        init_img_recon,_, d_vars = DiscriminatorCNN(init_img_orig,3,64,4,128,'NCHW') # BUG_need denorm\n",
    "\n",
    "        var = g_vars + d_vars\n",
    "\n",
    "        net = build_model(content_img, mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net2 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(mask, dtype=tf.float32))\n",
    "        net3 = build_model(content_img, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "        net4 = build_model(init_img_vgg, is_gen=True, mask = tf.constant(pixel_mask, dtype=tf.float32))\n",
    "    ########################### Loss ###########################\n",
    "    from time import time\n",
    "    t = time()\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver(var)\n",
    "    \n",
    "    \n",
    "    if Dataset == 'CelebA':\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('logs/CelebA_0517_071609/'))\n",
    "    #elif Dataset == 'Bedroom': # Wrong model(with Batchnorm)\n",
    "    #    saver.restore(sess, tf.train.latest_checkpoint('logs/Bedroom_0726_161928/'))\n",
    "    elif Dataset == 'Bedroom':\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('logs/Bedroom_0812_011108/'))\n",
    "    print(\"Cost time: %.2fs\"%(time() - t))\n",
    "\n",
    "    # content loss\n",
    "    L_content, loss_collections = sum_content_losses(sess, net, net2, net3, net4,\n",
    "                                                     content_img,\n",
    "                                                     content_layers=content_layers,\n",
    "                                                     content_layer_weights=content_weights,\n",
    "                                                     content_types = content_types,\n",
    "                                                     mask_types = mask_types\n",
    "                                                    )\n",
    "\n",
    "    # Discrim loss\n",
    "    if Dataset == 'CelebA':\n",
    "        discrim_loss = tf.reduce_mean(tf.abs(init_img_recon - init_img_orig) )\n",
    "    elif Dataset == 'Bedroom':\n",
    "        discrim_loss = - tf.reduce_mean(init_img_logits)\n",
    "\n",
    "    # total loss\n",
    "    L_total  = main_coef * L_content\n",
    "    alpha_var = tf.get_variable(name='alpha', dtype=tf.float32, initializer=alpha * 1.0)\n",
    "    L_total += alpha_var*discrim_loss\n",
    "    L_total += gamma*tf.reduce_mean(tf.abs(content_img_orig - init_img)*tf.constant((pixel_mask),dtype=tf.float32))\n",
    "    \n",
    "    ############################ optimization algorithm ###############################\n",
    "    init_z = paint_board\n",
    "\n",
    "\n",
    "\n",
    "    with tf.variable_scope('adam_optimizer') as vs:\n",
    "        optimizer = tf.train.AdamOptimizer(lr, beta1=b1, beta2=b2)\n",
    "#         optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "#         optimizer = tf.train.RMSPropOptimizer(lr)\n",
    "\n",
    "        gvs = optimizer.compute_gradients(L_total, var_list=[init_z])\n",
    "        gvs = [(grad+noise_coef*tf.random_normal(tf.shape(grad)), var) for grad, var in gvs]\n",
    "\n",
    "        train_op = optimizer.apply_gradients(gvs)\n",
    "        vars = tf.contrib.framework.get_variables(vs)\n",
    "    init_op = tf.initialize_variables(vars + [alpha_var])    \n",
    "\n",
    "    ########################### Session Run ##########################\n",
    "    output_data = []\n",
    "#     plot_img(content_img_orig/255.\n",
    "#                 ,save_path=os.path.join(root_path,'content.png')\n",
    "#                 ,show=SHOW_IMAGE\n",
    "#              )\n",
    "    for t in range(ntimes):\n",
    "        sess.run(init_op_paint_board)\n",
    "        sess.run(init_op)\n",
    "        i = sess.run(init_img)\n",
    "        grid_imgs = color_grid_vis(i)\n",
    "        rand = str(np.random.randint(10000))\n",
    "        plot_img(my_post(grid_imgs)\n",
    "                 ,title='Sample Img Init'\n",
    "                 ,save_path=os.path.join(root_path, 'samples_init.jpg')\n",
    "                 ,show=SHOW_IMAGE\n",
    "                )\n",
    "        train_loss = []\n",
    "        for iterations in trange(max_step):\n",
    "            sess.run(train_op)\n",
    "            if iterations % 100 == 0:\n",
    "                curr_loss = sess.run(L_total)\n",
    "                train_loss.append(curr_loss)\n",
    "                img = sess.run(init_img)\n",
    "                grid_imgs = color_grid_vis(img)\n",
    "\n",
    "                print(\"At iterate {}\\tf=  {:.4f}\".format(iterations, curr_loss))\n",
    "    #             loss = sess.run(loss_collections)\n",
    "    #             print(loss)\n",
    "                plot_img(my_post(grid_imgs)\n",
    "                         ,title='Sample Img Iter_%d'%iterations\n",
    "                         ,save_path=os.path.join(root_path, 'samples_iter_%d.png'%iterations)\n",
    "                         ,show=SHOW_IMAGE\n",
    "                        )\n",
    "            if iterations > 99:\n",
    "                if iterations % 100 == 0:\n",
    "                    alpha_var.assign(sess.run(alpha_var) * 1)\n",
    "        img = sess.run(init_img)\n",
    "        output_data.append(img)\n",
    "\n",
    "        grid_imgs = color_grid_vis(img)\n",
    "\n",
    "        print(\"At iterate {}\\tf=  {:.4f}\".format(iterations, curr_loss))\n",
    "        plot_img(my_post(grid_imgs)\n",
    "                 ,title='Sample Img Iter_%d'%iterations\n",
    "                 ,save_path=os.path.join(root_path, 'samples_iter_%d.png'%iterations)\n",
    "                 ,show=SHOW_IMAGE\n",
    "                )\n",
    "\n",
    "        ########################### Plot final learning result & write to file #####################\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(train_loss)) * 100, train_loss, color='blue', label='Train loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.xlabel('#Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        print('Final loss: %.4f'%train_loss[-1])\n",
    "        with open(os.path.join(root_path, 'hyperparameters.txt'), 'a') as f:\n",
    "            f.write('Final loss: %d\\n'%train_loss[-1])\n",
    "    output_data = np.concatenate(output_data)\n",
    "    for idx, pic in enumerate(output_data):\n",
    "        imsave(os.path.join(root_path, '%s.png'%str(idx).zfill(5)),my_post(pic) )\n",
    "    plot_result(content_img_orig, output_data, save_path = os.path.join(root_path,'results.png'))\n",
    "    ########################### Close Session & Reset Graph\n",
    "    tf.reset_default_graph()\n",
    "    #sess.close()\n",
    "    if Dataset == 'Bedroom':\n",
    "        lib.delete_all_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#     plot_img(my_post(img)\n",
    "#              ,save_path=os.path.join(root_path, '%s.jpg'%str(idx).zfill(5))\n",
    "#              ,show=SHOW_IMAGE\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SHOW_IMAGE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python msssim_Copy1.py --original_image=187628.jpg --compared_image=187627.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !python msssim.py --path=./ --nsamples=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
